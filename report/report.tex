
\documentclass[12pt]{article}
\usepackage[margin={3cm,3cm}]{geometry}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage{multicol}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue,
  citecolor=magenta,
  filecolor=magenta
}

\usepackage{amsmath}
\usepackage{algorithm2e}
\usepackage{appendix}


\title{Detecting and Flagging Self-Timing Code}
\author{Cameron Wong, Joe Doyle}

\begin{document}
\maketitle

\begin{abstract}
  With the advent of the SPECTRE vulnerability bringing new attention to
  hardware-level timing-based attacks, much research has gone into mitigating
  these at a software level. Most of these efforts approach the problem by
  disabling the attack vector entirely, but have so far shown to have serious
  performance ramifications. We implemented a source-level static taint
  analysis of C code that could detect and mark ``timed sections'' based on
  further analyses to recognize ``timer functions'', which might be extended to
  statically determine whether a given source is attempting to execute a
  timing-based attack.
\end{abstract}

\begin{multicols*}{2}
  \section{Introduction}
  ``Timing attacks'' are a broad category of attacks that can be used to
  covertly transmit information or inspect the internal state of a program by
  taking advantage of specific properties about the hardware. An important
  consequence about the physical nature of these attacks is that this can be
  used to bypass software-level protections by influencing hardware-internal
  processes and measuring the time taken to execute. The SPECTRE bug, for
  example, takes advantage of speculative execution and hardware caching
  effects to leak the contents of kernel memory.

  The ability of a well-constructed timing attack to escape software jails and
  sandboxes is especially concerning in the age of browsers, in which users
  routinely download and run untrusted scripts and programs (often unknowingly)
  while browsing the web. Several browsers have implemented internal changes to
  combat this (such as reducing clock precision and disabling shared memory
  primitives) that have proven to be somewhat effective. However, there do not
  appear to be many attempts to statically verify that certain sections of a
  given program are safe to execute. Most attempts are ``all-or-nothing'' --
  mitigation must be used with entire applications or not at all. This can be
  a deal-breaker in performance- or correctness-critical situations, thus
  exposing them to severe security vulnerabilities\footnote{See related work}.

  It is critical, however, that the perpetrator of a timing attack have some
  capability to measure the relative execution time of a particular procedure.
  The original SPECTRE paper, for example, uses calls to GCC's builtin
  \texttt{\_\_rtdscp} primitive to measure clock cycles taken to perform a
  particular malicious memory access\cite{spectrep}. Towards that end, we
  believe that it should be possible to statically detect and delineate between
  calls and stores of possible ``timer functions'' and use this data to apply
  further cache attack mitigation in a more fine-grained manner.

  \section{Background}

  \subsection{Timing Attacks}

  The subject of this work is primarily attacks intended to exploit
  hardware-based caches via analysis of the total execution time of the victim
  to leak secret information to an adversary\cite{Ge2018}. This is typically
  done by measuring the time taken to perform a large number of memory accesses
  within attacker-controlled code and inferring the total number of resulting
  cache hits and misses, which can then be used to guess unrelated information
  about the victim's internal state. The specifics of how exactly this is done
  and what information can be gleaned is specific to the attack and is far
  beyond the scope of this work. We are instead concerned with how and where
  the time is measured, which can be used to demarcate code sections that may
  be used for a timing-based attack.

  \subsection{Timing Channels}

  Unsurprisingly, a timing-based attack requires some way of recording the
  passage of time. This can be standard wall-clock time, but in practice there
  are any number of workable replacements. The only information of importance
  in this case is the \textit{relative time} in some units of necessary
  precision between two distinct program states, so any
  monotonically-increasing counter will, in theory, be sufficient\cite{Ge2018}.
  Of other interest is the distinction between
  concurrent and non-concurrent attacks, which distinguish whether the attacker
  is able to receive and react to information gained while the victim is
  executing\cite{lcache}. Currently, our implementation only properly
  detects non-concurrent attacks. However, there is nothing in particular about
  a concurrent timing-based attack that would require significant changes to
  our model, only more extensive further analysis.

  \subsection{Taint Analysis}

  Taint analysis is a technique used to narrow down a source of vulnerabilities
  by isolating what internal state can or cannot be influenced by untrusted
  input. This is typically done by examining the \textit{data flow} of a given
  piece of information -- if tainted object $X$ is used to compute the value of
  some value $Y$ under some execution flow, the resulting value is considered
  tainted by the untrusted $X$, and cannot necessarily be trusted
  itself\cite{taint}.

  We adjusted the definition of ``tainted'' in this case to refer specifically
  to objects and values computed using a timer function (as, in theory, the
  entire program is considered untrusted). However, the core principles still
  hold.

  \section{Threat Model}

  Attackers to our model will be working under the following constraints:

  \begin{itemize}
    \item Attacker may perform arbitrary local code execution within a defined
      environment via a known, untrusted channel. This environment may or may
      not be subject to external security measures such as operating system
      permissions, sandboxing, etc.
    \item No access to underlying hardware or operating system. This eliminates
      the possibility of other side channels, such as power consumption or
      sound analysis.
  \end{itemize}

  We believe this to be a realistic threat model, as it can be fitted to
  common attack vectors in real systems, such as

  \begin{itemize}
    \item Malicious Javascript injection into websites, executed via browser
    \item Malicious code published via a large package or dependency manager
  \end{itemize}

  \section{Solution}

  Let $E$ be the set of expressions within our language.

  Suppose that we have defined some trusted \textit{timer detection function}
  $f: E \rightarrow \{\texttt{true}, \texttt{false}\}$ that can be used freely
  within the analysis\footnote{Our implementation is a simple string
  comparison, but can be theoretically expanded to arbitrary analyses}.

  For the purposes of this analysis, we will consider an \textit{output} of a
  function to be any observable, concrete result (such as a print statement,
  a server response, direct return value, etc).

  We can define our taint flow as follows:

  \begin{itemize}
    \item Any expression $e$ is considered tainted by itself if $f(e)$.
    \item If a subexpression $e'$ of $e$ is tainted, then $e$ is tainted by
      $e'$.
    \item For an assignable $x$, if there exists a reachable command
      $n = assign(x,e)$ where $e$ is tainted, then $x$ is tainted by $e$.
  \end{itemize}

  Finally, we consider an output of the procedure to be a potential leak if
  it is tainted by at least two unique nodes. We define the
  \textit{critical section} of this value to be the possible control flow
  paths between any two taint sites. Once the dataflow analysis is complete, we
  can output these sections ourselves.

  \section{Results}

  Our proof-of-concept implementation is currently written in Haskell to
  analyze C; a more practical version might instead target arbitrary
  Javascript. We also were unable to produce a particularly sophisticated
  timer analysis function $f$; we instead did a simple string comparison on
  function call name.

  We wrote two implementations of common cache-based timing attacks as input
  data:
  \begin{itemize}
    \item
  \href{https://github.com/jpdoyle/static-analysis-project/blob/master/clock-analysis/data/cache-size.c}
      {cache-size.c}

    \item
      \href{https://github.com/jpdoyle/static-analysis-project/blob/master/clock-analysis/data/nproc.c}
      {nproc.c}
  \end{itemize}

  \begin{itemize}

    \item \texttt{cache-size.c}

      Our analysis correctly reports the
  critical sections between lines 43 and 52 by identifying the relevant dirty
  variable \texttt{time\_taken} used to compute the output. It also identifies
  the section between lines 73 and 78.

  Our analysis currently also (erroneously) marks sections between 43 and 73,
  52 and 73 (etc) as possible critical sections. This is technically correct
  under the analysis, but not necessarily useful in this case. Improving the
  accuracy of the results will be a concern moing forwards.

      Finally, we were able to correctly identify the variables \texttt{t1},
      \texttt{t2}, \texttt{t3} and \texttt{t4} as variables containing timer
      state.

    \item \texttt{nproc.c}

      We correctly detect the critical timed section between lines 39 and 46,
      identifying \texttt{t1} and \texttt{t2} as the relevant timer variables.
  \end{itemize}

  All of our source code can be found on Github in the repository

  \href{https://github.com/jpdoyle/static-analysis-project}{jpdoyle/static-analysis-project}

  \section{Limitations and Future Work}

  \subsubsection*{Timer Function Detection.}

  The obvious flaw is, of course, the necessity for a sophisticated timer
  detection function. At the present, we were unable to produce a working
  static method to detect monotonically increasing functions for use as timers.
  We believe that current standard dataflow techniques are capable of detecting
  such, but we encountered difficulty in analyzing functions in the presence
  of multiple threads (such as the timer in \texttt{nproc.c}).

  \subsubsection*{Intraprocedural Analysis.}

  Our work is currently limited to analyzing single procedures. This is
  unrealistic for real-world use cases, but there is nothing inherent to our
  analysis that prevents it from being expanded to work intraprocedurally as
  well.

  \section{Related Work}

  \subsubsection*{Cache Side Channel Elimination.}

  There has been significant work into
  developing lightweight methods to eliminate cache-based timing side channels
  entirely via lazy cleansing of shared state before handing control over to
  untrusted processes\cite{lcache}. We believe our work to be orthogonal to
  this in that Braun et al's work is largely targeted at mitigation at a
  blue-team (defending) source level, whereas our work is targeted at detecting
  red-team (attacking) efforts at the source level. The proposed  mitigations
  require the ability to inspect and update the source code of
  security-critical applications to insert the necessary source annotations to
  demarcate secret sections. Our approach, while possibly less effective, is
  more conducive to higher-level defense layers that can be applied on top of
  applications for which adding the proposed source annotations is infeasible
  or impossible.

  \subsubsection*{Retpoline and other software approaches}

  Google has released a mitigation strategy known as retpoline\cite{retpoline}
  that can inject software constructs into otherwise-vulnerable code to
  undirect speculative execution and avoid the cache-related issues. Similar
  work has been done by various compilers and service manufacturers\cite{gcc}
  \cite{msft}. Much of this work, however, must be done at compile time or
  require extensive other measures. Similar to above, we expect extensions of
  our work to instead be used to implement an ``outer layer'' around sensitive
  applications without necessitating modifying the application itself.

  \subsubsection*{Robust Static Cache Analysis.}

  Doychev and Kopf implemented an automated static countermeasure against
  cache-based side channel attacks in executable code\cite{rigor}. However,
  they appeared to be focused on analyzing the flow of cache memory itself,
  checking reads or writes to potentially cached memory addresses to determine
  what information may be leaked. As their implementation is a whole-program
  analysis, we belive that our work can be used to supplement theirs by
  directing attention to relevant fields.

  \section{Conclusion}

  With modern technologies allowing more and more precise timing capabilities,
  statically detecting self-timed code sections will be of increasing
  importance in the future. Many current software approaches to combating
  these attacks (clock jitter, code injection) have significant impacts on
  non-security issues, such as benchmarking or similar time-critical
  applications. However, such measures need not be taken at the application
  level. Any long-term security solution should be multifaceted and
  multilayered.

  As we are simply presenting a proof of concept, we are unsure of the direct
  applications our work may have in the future, as well as the impacts thereof.
  Current computer systems often rely heavily on running unvetted code from
  only partially-trusted sources. By directing efforts towards automatic,
  course-grained security verification of untrusted code, however, the human
  burden of securing dependencies can be somewhat alleviated. We found it
  extremely feasible to flag possibly untrusted timed code sections, the key
  capability of a timing-based attacker, and hope to use it to eliminate
  such vulnerabilities in the future.
\end{multicols*}

\bibliographystyle{IEEEtran}
\bibliography{spect}
\end{document}

